# æœ€å…ˆè¿›å’Œæœ€å‡†ç¡®çš„è§†é¢‘è´¨é‡è¯„ä¼°æ¡†æ¶ - å¯ç›´æ¥è°ƒç”¨æŒ‡å—

åŸºäºè®ºæ–‡ç ”ç©¶å’Œæœ€æ–°æŠ€æœ¯å‘å±•ï¼Œæœ¬æ–‡æ¡£åˆ—å‡ºäº†æœ€å…ˆè¿›ã€æœ€å‡†ç¡®ä¸”å¯ä»¥ç›´æ¥è°ƒç”¨çš„æ¡†æ¶ã€‚

---

## ä¸€ã€æ¡†æ¶å…ˆè¿›æ€§å’Œå‡†ç¡®æ€§æ’å

### ğŸ¥‡ ç¬¬ä¸€æ¢¯é˜Ÿï¼šæœ€å…ˆè¿›ä¸”å¯ç›´æ¥è°ƒç”¨

#### 1. **VMAF (Video Multi-Method Assessment Fusion)**
- **å…ˆè¿›æ€§**ï¼šâ­â­â­â­â­ (5/5)
- **å‡†ç¡®æ€§**ï¼šâ­â­â­â­â­ (5/5)
- **æ˜“ç”¨æ€§**ï¼šâ­â­â­â­â­ (5/5)
- **å¼€å‘è€…**ï¼šNetflix
- **çŠ¶æ€**ï¼šâœ… å¯ç›´æ¥è°ƒç”¨ï¼Œæˆç†Ÿç¨³å®š

**ä¸ºä»€ä¹ˆæœ€å…ˆè¿›ï¼š**
- ç»“åˆå¤šç§è´¨é‡è¯„ä¼°æ–¹æ³•ï¼ˆè§†è§‰ä¿¡æ¯ä¿çœŸåº¦ã€ç»†èŠ‚æŸå¤±ã€æ—¶é—´ä¿¡æ¯ï¼‰
- åŸºäºæœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œç»è¿‡å¤§è§„æ¨¡ä¸»è§‚æµ‹è¯•è®­ç»ƒ
- åœ¨è§†é¢‘ç¼–ç ã€æµåª’ä½“é¢†åŸŸå¹¿æ³›åº”ç”¨ï¼ŒéªŒè¯å……åˆ†
- æŒç»­æ›´æ–°ï¼Œæ”¯æŒæœ€æ–°è§†é¢‘æ ¼å¼

**ç›´æ¥è°ƒç”¨æ–¹æ³•ï¼š**
```bash
# å®‰è£…
pip install vmaf
```

```python
# Pythonè°ƒç”¨ç¤ºä¾‹
import vmaf
from vmaf import vmaf_exec

# æ–¹æ³•1ï¼šä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·ï¼ˆæœ€ç®€å•ï¼‰
result = vmaf_exec.run_vmaf(
    reference_video='reference.mp4',
    distorted_video='test.mp4',
    model_path='vmaf_v0.6.1.pkl'
)

# æ–¹æ³•2ï¼šä½¿ç”¨Python API
from vmaf import vmaf_exec

result = vmaf_exec.run_vmaf(
    reference_video='reference.mp4',
    distorted_video='test.mp4',
    model_path='vmaf_v0.6.1.pkl',
    log_file_path='vmaf_log.json'
)

print(f"VMAF Score: {result['aggregate']['VMAF_score']}")
```

---

#### 2. **LPIPS (Learned Perceptual Image Patch Similarity)**
- **å…ˆè¿›æ€§**ï¼šâ­â­â­â­â­ (5/5)
- **å‡†ç¡®æ€§**ï¼šâ­â­â­â­â­ (5/5)
- **æ˜“ç”¨æ€§**ï¼šâ­â­â­â­â­ (5/5)
- **å¼€å‘è€…**ï¼šRichard Zhang (Berkeley)
- **çŠ¶æ€**ï¼šâœ… å¯ç›´æ¥è°ƒç”¨ï¼Œæœ‰å®˜æ–¹PyPIåŒ…

**ä¸ºä»€ä¹ˆæœ€å…ˆè¿›ï¼š**
- åŸºäºæ·±åº¦å­¦ä¹ çš„æ„ŸçŸ¥ç›¸ä¼¼åº¦è¯„ä¼°
- æ›´ç¬¦åˆäººç±»è§†è§‰æ„ŸçŸ¥ï¼Œæ¯”ä¼ ç»ŸPSNR/SSIMæ›´å‡†ç¡®
- æ”¯æŒå¤šç§é¢„è®­ç»ƒæ¨¡å‹ï¼ˆAlexNet, VGG, SqueezeNetï¼‰
- åœ¨å­¦æœ¯ç•Œå’Œå·¥ä¸šç•Œå¹¿æ³›ä½¿ç”¨

**ç›´æ¥è°ƒç”¨æ–¹æ³•ï¼š**
```bash
# å®‰è£…ï¼ˆæœ€ç®€å•ï¼‰
pip install lpips
```

```python
# Pythonè°ƒç”¨ç¤ºä¾‹
import lpips
import torch
from PIL import Image

# åˆå§‹åŒ–æ¨¡å‹ï¼ˆé€‰æ‹©ç½‘ç»œï¼‰
loss_fn = lpips.LPIPS(net='alex')  # å¯é€‰: 'alex', 'vgg', 'squeeze'
# æˆ–ä½¿ç”¨é»˜è®¤ï¼ˆalexï¼‰
loss_fn = lpips.LPIPS()

# åŠ è½½å›¾åƒ
img0 = lpips.im2tensor(lpips.load_image('img0.jpg'))
img1 = lpips.im2tensor(lpips.load_image('img1.jpg'))

# è®¡ç®—LPIPSè·ç¦»ï¼ˆå€¼è¶Šå°è¶Šç›¸ä¼¼ï¼Œ0-1èŒƒå›´ï¼‰
distance = loss_fn(img0, img1)
print(f"LPIPS Distance: {distance.item():.4f}")

# è§†é¢‘å¸§é—´è¯„ä¼°
import cv2

def calculate_video_lpips(video_path: str) -> dict:
    """è®¡ç®—è§†é¢‘å¸§é—´çš„LPIPSè·ç¦»"""
    loss_fn = lpips.LPIPS(net='alex')
    cap = cv2.VideoCapture(video_path)
    
    prev_frame = None
    lpips_scores = []
    frame_count = 0
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # è½¬æ¢ä¸ºRGB
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        frame_tensor = lpips.im2tensor(frame_rgb)
        
        if prev_frame is not None:
            distance = loss_fn(prev_frame, frame_tensor)
            lpips_scores.append(distance.item())
        
        prev_frame = frame_tensor
        frame_count += 1
    
    cap.release()
    
    return {
        'mean_lpips': float(np.mean(lpips_scores)),
        'std_lpips': float(np.std(lpips_scores)),
        'min_lpips': float(np.min(lpips_scores)),
        'max_lpips': float(np.max(lpips_scores)),
        'scores': lpips_scores,
        'frame_count': frame_count
    }
```

---

#### 3. **IQA-PyTorch (ç»¼åˆå›¾åƒè´¨é‡è¯„ä¼°å·¥å…·ç®±)**
- **å…ˆè¿›æ€§**ï¼šâ­â­â­â­â­ (5/5)
- **å‡†ç¡®æ€§**ï¼šâ­â­â­â­â­ (5/5)
- **æ˜“ç”¨æ€§**ï¼šâ­â­â­â­â­ (5/5)
- **å¼€å‘è€…**ï¼šå¼€æºç¤¾åŒº
- **çŠ¶æ€**ï¼šâœ… å¯ç›´æ¥è°ƒç”¨ï¼ŒåŒ…å«å¤šç§æŒ‡æ ‡

**ä¸ºä»€ä¹ˆæœ€å…ˆè¿›ï¼š**
- é›†æˆäº†å¤šç§å…ˆè¿›çš„å›¾åƒè´¨é‡è¯„ä¼°æŒ‡æ ‡
- æ”¯æŒGPUåŠ é€Ÿ
- ç»Ÿä¸€çš„APIæ¥å£ï¼Œæ˜“äºä½¿ç”¨
- åŒ…å«LPIPSã€FIDã€NIQEç­‰å¤šç§æŒ‡æ ‡

**ç›´æ¥è°ƒç”¨æ–¹æ³•ï¼š**
```bash
# å®‰è£…
pip install pyiqa
```

```python
# Pythonè°ƒç”¨ç¤ºä¾‹
import pyiqa
import torch

# åˆå§‹åŒ–æŒ‡æ ‡
lpips_metric = pyiqa.create_metric('lpips', device=torch.device('cuda'))
fid_metric = pyiqa.create_metric('fid', device=torch.device('cuda'))
niqe_metric = pyiqa.create_metric('niqe', device=torch.device('cuda'))

# è®¡ç®—æŒ‡æ ‡
img1 = torch.randn(1, 3, 224, 224)
img2 = torch.randn(1, 3, 224, 224)

lpips_score = lpips_metric(img1, img2)
print(f"LPIPS: {lpips_score.item()}")
```

---

### ğŸ¥ˆ ç¬¬äºŒæ¢¯é˜Ÿï¼šå…ˆè¿›ä½†éœ€è¦ä¸€äº›é…ç½®

#### 4. **FVD (Frechet Video Distance)**
- **å…ˆè¿›æ€§**ï¼šâ­â­â­â­â­ (5/5)
- **å‡†ç¡®æ€§**ï¼šâ­â­â­â­â­ (5/5)
- **æ˜“ç”¨æ€§**ï¼šâ­â­â­â­ (4/5)
- **å¼€å‘è€…**ï¼šGoogle Research
- **çŠ¶æ€**ï¼šâš ï¸ éœ€è¦ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹ï¼Œä½†å¯ç›´æ¥è°ƒç”¨

**ä¸ºä»€ä¹ˆå…ˆè¿›ï¼š**
- ä¸“é—¨ä¸ºç”Ÿæˆè§†é¢‘è®¾è®¡
- åŸºäºI3Dæ¨¡å‹æå–ç‰¹å¾ï¼Œè¯„ä¼°è§†é¢‘åˆ†å¸ƒ
- åœ¨è§†é¢‘ç”Ÿæˆä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚

**ç›´æ¥è°ƒç”¨æ–¹æ³•ï¼š**
```bash
# æ–¹æ³•1ï¼šä½¿ç”¨ç¬¬ä¸‰æ–¹å®ç°ï¼ˆæ¨èï¼‰
pip install tensorflow tensorflow-hub

# æ–¹æ³•2ï¼šä½¿ç”¨PyTorchå®ç°
# éœ€è¦ä»GitHubå…‹éš†
git clone https://github.com/universome/fvd.git
cd fvd
pip install -e .
```

```python
# Pythonè°ƒç”¨ç¤ºä¾‹ï¼ˆTensorFlowç‰ˆæœ¬ï¼‰
import tensorflow as tf
import tensorflow_hub as hub
import numpy as np

# åŠ è½½I3Dæ¨¡å‹
i3d_model = hub.load("https://tfhub.dev/deepmind/i3d-kinetics-400/1")

def calculate_fvd(video1, video2):
    """è®¡ç®—FVDè·ç¦»"""
    # æå–ç‰¹å¾
    features1 = i3d_model(video1)
    features2 = i3d_model(video2)
    
    # è®¡ç®—FrÃ©chetè·ç¦»
    mu1, sigma1 = np.mean(features1, axis=0), np.cov(features1.T)
    mu2, sigma2 = np.mean(features2, axis=0), np.cov(features2.T)
    
    # FVDè®¡ç®—
    fvd = calculate_frechet_distance(mu1, sigma1, mu2, sigma2)
    return fvd

# æˆ–ä½¿ç”¨PyTorchç‰ˆæœ¬ï¼ˆæ›´ç®€å•ï¼‰
from fvd import calculate_fvd

fvd_score = calculate_fvd(
    video1_path='video1.mp4',
    video2_path='video2.mp4',
    device='cuda'
)
print(f"FVD Score: {fvd_score}")
```

---

#### 5. **CLIPScore**
- **å…ˆè¿›æ€§**ï¼šâ­â­â­â­ (4/5)
- **å‡†ç¡®æ€§**ï¼šâ­â­â­â­ (4/5)
- **æ˜“ç”¨æ€§**ï¼šâ­â­â­â­â­ (5/5)
- **å¼€å‘è€…**ï¼šåŸºäºOpenAI CLIP
- **çŠ¶æ€**ï¼šâœ… å¯ç›´æ¥è°ƒç”¨

**ä¸ºä»€ä¹ˆå…ˆè¿›ï¼š**
- åŸºäºCLIPæ¨¡å‹ï¼Œè¯„ä¼°è¯­ä¹‰ä¸€è‡´æ€§
- å¯ä»¥è¯„ä¼°è§†é¢‘å†…å®¹ä¸æ–‡æœ¬æè¿°çš„åŒ¹é…åº¦
- é€‚åˆAIç”Ÿæˆè§†é¢‘çš„è¯­ä¹‰è¯„ä¼°

**ç›´æ¥è°ƒç”¨æ–¹æ³•ï¼š**
```bash
# å®‰è£…
pip install clip-score
```

```python
# Pythonè°ƒç”¨ç¤ºä¾‹
from clipscore import clipscore
import cv2

# å•å›¾åƒè¯„ä¼°
score = clipscore.compute_clipscore(
    image_path='image.jpg',
    caption='a beautiful sunset'
)
print(f"CLIPScore: {score}")

# è§†é¢‘è¯„ä¼°
def evaluate_video_clipscore(video_path: str, prompt: str) -> dict:
    """è¯„ä¼°è§†é¢‘ä¸æç¤ºè¯çš„CLIPScore"""
    cap = cv2.VideoCapture(video_path)
    scores = []
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # ä¿å­˜ä¸´æ—¶å›¾åƒ
        cv2.imwrite('temp_frame.jpg', frame)
        
        # è®¡ç®—CLIPScore
        score = clipscore.compute_clipscore('temp_frame.jpg', prompt)
        scores.append(score)
    
    cap.release()
    
    return {
        'mean_clipscore': float(np.mean(scores)),
        'std_clipscore': float(np.std(scores)),
        'scores': scores
    }
```

---

## äºŒã€æ¨èé›†æˆæ–¹æ¡ˆï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰

### ğŸ¯ æ–¹æ¡ˆ1ï¼šå¿«é€Ÿé›†æˆï¼ˆæ¨èæ–°æ‰‹ï¼‰

**é€‰æ‹©æ¡†æ¶ï¼š**
1. **LPIPS** - æœ€ç®€å•ï¼Œç›´æ¥pip install
2. **VMAF** - æˆç†Ÿç¨³å®šï¼ŒNetflixç»´æŠ¤

**å®‰è£…å‘½ä»¤ï¼š**
```bash
pip install lpips vmaf
```

**ä¼˜åŠ¿ï¼š**
- å®‰è£…ç®€å•ï¼Œæ— éœ€é¢å¤–é…ç½®
- æ–‡æ¡£å®Œå–„ï¼Œç¤¾åŒºæ”¯æŒå¥½
- é€‚åˆå¿«é€ŸéªŒè¯å’ŒåŸå‹å¼€å‘

---

### ğŸ¯ æ–¹æ¡ˆ2ï¼šå…¨é¢é›†æˆï¼ˆæ¨èç”Ÿäº§ç¯å¢ƒï¼‰

**é€‰æ‹©æ¡†æ¶ï¼š**
1. **VMAF** - è§†é¢‘è´¨é‡è¯„ä¼°é‡‘æ ‡å‡†
2. **LPIPS** - æ„ŸçŸ¥ç›¸ä¼¼åº¦è¯„ä¼°
3. **IQA-PyTorch** - ç»¼åˆå·¥å…·ç®±
4. **CLIPScore** - è¯­ä¹‰ä¸€è‡´æ€§è¯„ä¼°

**å®‰è£…å‘½ä»¤ï¼š**
```bash
pip install vmaf lpips pyiqa clip-score
```

**ä¼˜åŠ¿ï¼š**
- è¦†ç›–å¤šä¸ªè¯„ä¼°ç»´åº¦
- å¯ä»¥å¯¹æ¯”ä¸åŒæŒ‡æ ‡
- é€‚åˆå…¨é¢çš„è´¨é‡è¯„ä¼°

---

### ğŸ¯ æ–¹æ¡ˆ3ï¼šä¸“ä¸šé›†æˆï¼ˆæ¨èç ”ç©¶/é«˜çº§åº”ç”¨ï¼‰

**é€‰æ‹©æ¡†æ¶ï¼š**
1. **VMAF** - è§†é¢‘è´¨é‡
2. **LPIPS** - æ„ŸçŸ¥ç›¸ä¼¼åº¦
3. **FVD** - ç”Ÿæˆè§†é¢‘ä¸“ç”¨
4. **CLIPScore** - è¯­ä¹‰è¯„ä¼°
5. **IQA-PyTorch** - ç»¼åˆå·¥å…·

**å®‰è£…å‘½ä»¤ï¼š**
```bash
pip install vmaf lpips pyiqa clip-score
pip install tensorflow tensorflow-hub  # ç”¨äºFVD
# æˆ–
git clone https://github.com/universome/fvd.git
cd fvd && pip install -e .
```

**ä¼˜åŠ¿ï¼š**
- æœ€å…¨é¢çš„è¯„ä¼°ä½“ç³»
- é€‚åˆç ”ç©¶å’Œæ·±åº¦åˆ†æ
- å¯ä»¥å‘è¡¨è®ºæ–‡çº§åˆ«çš„ç»“æœ

---

## ä¸‰ã€å®é™…è°ƒç”¨ç¤ºä¾‹ï¼ˆé›†æˆåˆ°Video-Evalï¼‰

### åˆ›å»ºæ–°æ¨¡å—ï¼š`advanced_quality_metrics.py`

```python
"""
é«˜çº§è§†é¢‘è´¨é‡è¯„ä¼°æŒ‡æ ‡
é›†æˆVMAFã€LPIPSã€FVDã€CLIPScoreç­‰æœ€å…ˆè¿›çš„æŒ‡æ ‡
"""

import numpy as np
import cv2
from pathlib import Path
from typing import Dict, Optional, List
import sys

class AdvancedQualityMetrics:
    """é«˜çº§è§†é¢‘è´¨é‡è¯„ä¼°ç±»"""
    
    def __init__(self, video_path: str):
        self.video_path = Path(video_path)
        if not self.video_path.exists():
            raise FileNotFoundError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
    
    def calculate_lpips(self) -> Dict:
        """
        è®¡ç®—è§†é¢‘å¸§é—´çš„LPIPSè·ç¦»
        
        Returns:
            åŒ…å«LPIPSç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        """
        try:
            import lpips
        except ImportError:
            raise ImportError(
                "LPIPSæœªå®‰è£…ã€‚è¯·å®‰è£…: pip install lpips\n"
                "LPIPSæ˜¯æœ€å…ˆè¿›çš„æ„ŸçŸ¥ç›¸ä¼¼åº¦è¯„ä¼°æŒ‡æ ‡ä¹‹ä¸€"
            )
        
        loss_fn = lpips.LPIPS(net='alex')
        cap = cv2.VideoCapture(str(self.video_path))
        
        if not cap.isOpened():
            raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {self.video_path}")
        
        prev_frame = None
        lpips_scores = []
        frame_count = 0
        
        print("æ­£åœ¨è®¡ç®—LPIPS...", file=sys.stderr)
        
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                frame_tensor = lpips.im2tensor(frame_rgb)
                
                if prev_frame is not None:
                    distance = loss_fn(prev_frame, frame_tensor)
                    lpips_scores.append(distance.item())
                
                prev_frame = frame_tensor
                frame_count += 1
                
                if frame_count % 30 == 0:
                    print(f"  å·²å¤„ç† {frame_count} å¸§", file=sys.stderr, end='\r')
            
            print("", file=sys.stderr)
            
            if not lpips_scores:
                return {'error': 'æ— æ³•è®¡ç®—LPIPSï¼Œè§†é¢‘å¯èƒ½åªæœ‰ä¸€å¸§'}
            
            return {
                'mean_lpips': float(np.mean(lpips_scores)),
                'std_lpips': float(np.std(lpips_scores)),
                'min_lpips': float(np.min(lpips_scores)),
                'max_lpips': float(np.max(lpips_scores)),
                'median_lpips': float(np.median(lpips_scores)),
                'frame_count': frame_count,
                'scores': lpips_scores[:100]  # åªä¿å­˜å‰100ä¸ª
            }
        finally:
            cap.release()
    
    def calculate_vmaf(self, reference_video: str) -> Dict:
        """
        ä½¿ç”¨VMAFè¯„ä¼°è§†é¢‘è´¨é‡ï¼ˆéœ€è¦å‚è€ƒè§†é¢‘ï¼‰
        
        Args:
            reference_video: å‚è€ƒè§†é¢‘è·¯å¾„
            
        Returns:
            åŒ…å«VMAFåˆ†æ•°çš„å­—å…¸
        """
        try:
            from vmaf import vmaf_exec
        except ImportError:
            raise ImportError(
                "VMAFæœªå®‰è£…ã€‚è¯·å®‰è£…: pip install vmaf\n"
                "VMAFæ˜¯Netflixå¼€å‘çš„æœ€å…ˆè¿›çš„è§†é¢‘è´¨é‡è¯„ä¼°å·¥å…·"
            )
        
        reference_path = Path(reference_video)
        if not reference_path.exists():
            raise FileNotFoundError(f"å‚è€ƒè§†é¢‘ä¸å­˜åœ¨: {reference_video}")
        
        print("æ­£åœ¨è®¡ç®—VMAF...", file=sys.stderr)
        
        try:
            result = vmaf_exec.run_vmaf(
                reference_video=str(reference_path),
                distorted_video=str(self.video_path),
                model_path='vmaf_v0.6.1.pkl'
            )
            
            return {
                'vmaf_score': float(result['aggregate']['VMAF_score']),
                'method': 'VMAF (Netflix)',
                'details': result
            }
        except Exception as e:
            return {
                'error': str(e),
                'method': 'VMAF (Netflix)'
            }
    
    def calculate_clipscore(self, prompt: str) -> Dict:
        """
        è®¡ç®—è§†é¢‘ä¸æ–‡æœ¬æç¤ºè¯çš„CLIPScore
        
        Args:
            prompt: æ–‡æœ¬æè¿°
            
        Returns:
            åŒ…å«CLIPScoreçš„å­—å…¸
        """
        try:
            from clipscore import clipscore
        except ImportError:
            raise ImportError(
                "CLIPScoreæœªå®‰è£…ã€‚è¯·å®‰è£…: pip install clip-score\n"
                "CLIPScoreç”¨äºè¯„ä¼°è§†é¢‘å†…å®¹ä¸æ–‡æœ¬æè¿°çš„è¯­ä¹‰ä¸€è‡´æ€§"
            )
        
        cap = cv2.VideoCapture(str(self.video_path))
        if not cap.isOpened():
            raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {self.video_path}")
        
        scores = []
        frame_count = 0
        
        print("æ­£åœ¨è®¡ç®—CLIPScore...", file=sys.stderr)
        
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # ä¿å­˜ä¸´æ—¶å›¾åƒ
                temp_path = f'temp_frame_{frame_count}.jpg'
                cv2.imwrite(temp_path, frame)
                
                try:
                    score = clipscore.compute_clipscore(temp_path, prompt)
                    scores.append(score)
                finally:
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    Path(temp_path).unlink(missing_ok=True)
                
                frame_count += 1
                
                if frame_count % 10 == 0:
                    print(f"  å·²å¤„ç† {frame_count} å¸§", file=sys.stderr, end='\r')
            
            print("", file=sys.stderr)
            
            if not scores:
                return {'error': 'æ— æ³•è®¡ç®—CLIPScore'}
            
            return {
                'mean_clipscore': float(np.mean(scores)),
                'std_clipscore': float(np.std(scores)),
                'min_clipscore': float(np.min(scores)),
                'max_clipscore': float(np.max(scores)),
                'frame_count': frame_count,
                'scores': scores[:50]  # åªä¿å­˜å‰50ä¸ª
            }
        finally:
            cap.release()
    
    def comprehensive_analysis(self, 
                             reference_video: Optional[str] = None,
                             prompt: Optional[str] = None) -> Dict:
        """
        ç»¼åˆè´¨é‡è¯„ä¼°ï¼ˆé›†æˆå¤šç§æœ€å…ˆè¿›çš„æŒ‡æ ‡ï¼‰
        
        Args:
            reference_video: å‚è€ƒè§†é¢‘è·¯å¾„ï¼ˆç”¨äºVMAFï¼‰
            prompt: æ–‡æœ¬æç¤ºè¯ï¼ˆç”¨äºCLIPScoreï¼‰
            
        Returns:
            åŒ…å«æ‰€æœ‰æŒ‡æ ‡çš„ç»¼åˆç»“æœ
        """
        result = {
            'video_path': str(self.video_path),
            'metrics': {}
        }
        
        # 1. LPIPSè¯„ä¼°ï¼ˆæ— éœ€å‚è€ƒï¼Œæœ€æ¨èï¼‰
        print("\n[1/3] è®¡ç®—LPIPSï¼ˆæ„ŸçŸ¥ç›¸ä¼¼åº¦ï¼‰...", file=sys.stderr)
        try:
            lpips_result = self.calculate_lpips()
            result['metrics']['lpips'] = lpips_result
            print("âœ“ LPIPSè®¡ç®—å®Œæˆ", file=sys.stderr)
        except Exception as e:
            result['metrics']['lpips'] = {'error': str(e)}
            print(f"âœ— LPIPSè®¡ç®—å¤±è´¥: {e}", file=sys.stderr)
        
        # 2. VMAFè¯„ä¼°ï¼ˆéœ€è¦å‚è€ƒè§†é¢‘ï¼‰
        if reference_video:
            print("\n[2/3] è®¡ç®—VMAFï¼ˆè§†é¢‘è´¨é‡ï¼‰...", file=sys.stderr)
            try:
                vmaf_result = self.calculate_vmaf(reference_video)
                result['metrics']['vmaf'] = vmaf_result
                print("âœ“ VMAFè®¡ç®—å®Œæˆ", file=sys.stderr)
            except Exception as e:
                result['metrics']['vmaf'] = {'error': str(e)}
                print(f"âœ— VMAFè®¡ç®—å¤±è´¥: {e}", file=sys.stderr)
        
        # 3. CLIPScoreè¯„ä¼°ï¼ˆéœ€è¦æ–‡æœ¬æç¤ºï¼‰
        if prompt:
            print("\n[3/3] è®¡ç®—CLIPScoreï¼ˆè¯­ä¹‰ä¸€è‡´æ€§ï¼‰...", file=sys.stderr)
            try:
                clipscore_result = self.calculate_clipscore(prompt)
                result['metrics']['clipscore'] = clipscore_result
                print("âœ“ CLIPScoreè®¡ç®—å®Œæˆ", file=sys.stderr)
            except Exception as e:
                result['metrics']['clipscore'] = {'error': str(e)}
                print(f"âœ— CLIPScoreè®¡ç®—å¤±è´¥: {e}", file=sys.stderr)
        
        return result


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == '__main__':
    import json
    
    # åˆ›å»ºè¯„ä¼°å™¨
    evaluator = AdvancedQualityMetrics('test_video.mp4')
    
    # ç»¼åˆè¯„ä¼°
    result = evaluator.comprehensive_analysis(
        reference_video='reference.mp4',  # å¯é€‰
        prompt='a beautiful sunset'  # å¯é€‰
    )
    
    # è¾“å‡ºç»“æœ
    print("\n" + "="*60)
    print("ç»¼åˆè´¨é‡è¯„ä¼°ç»“æœ")
    print("="*60)
    print(json.dumps(result, indent=2, ensure_ascii=False))
```

---

## å››ã€å¿«é€Ÿå¼€å§‹ï¼ˆæ¨èé…ç½®ï¼‰

### 1. å®‰è£…æœ€æ¨èçš„æ¡†æ¶

```bash
# æœ€å…ˆè¿›ä¸”å¯ç›´æ¥è°ƒç”¨çš„æ¡†æ¶
pip install lpips vmaf clip-score

# å¯é€‰ï¼šç»¼åˆå·¥å…·ç®±
pip install pyiqa
```

### 2. æµ‹è¯•å®‰è£…

```python
# test_advanced_metrics.py
def test_imports():
    """æµ‹è¯•æ‰€æœ‰åº“æ˜¯å¦æ­£ç¡®å®‰è£…"""
    frameworks = {
        'LPIPS': 'lpips',
        'VMAF': 'vmaf',
        'CLIPScore': 'clipscore',
        'IQA-PyTorch': 'pyiqa'
    }
    
    for name, module in frameworks.items():
        try:
            __import__(module)
            print(f"âœ“ {name} - å·²å®‰è£…ï¼Œå¯ä»¥ç›´æ¥è°ƒç”¨")
        except ImportError:
            print(f"âœ— {name} - æœªå®‰è£…ï¼Œè¿è¡Œ: pip install {module}")

if __name__ == '__main__':
    test_imports()
```

---

## äº”ã€æ€»ç»“ï¼šå¯ç›´æ¥è°ƒç”¨çš„æœ€å…ˆè¿›æ¡†æ¶

| æ¡†æ¶ | å…ˆè¿›æ€§ | å‡†ç¡®æ€§ | æ˜“ç”¨æ€§ | å¯ç›´æ¥è°ƒç”¨ | æ¨èåº¦ |
|------|--------|--------|--------|------------|--------|
| **VMAF** | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ | âœ… æ˜¯ | â­â­â­â­â­ |
| **LPIPS** | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ | âœ… æ˜¯ | â­â­â­â­â­ |
| **IQA-PyTorch** | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ | âœ… æ˜¯ | â­â­â­â­â­ |
| **CLIPScore** | â­â­â­â­ | â­â­â­â­ | â­â­â­â­â­ | âœ… æ˜¯ | â­â­â­â­ |
| **FVD** | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­ | âš ï¸ éœ€è¦é…ç½® | â­â­â­â­ |

### ğŸ¯ æœ€ç»ˆæ¨è

**æœ€æ¨èç›´æ¥ä½¿ç”¨çš„ä¸‰ä¸ªæ¡†æ¶ï¼š**
1. **LPIPS** - æœ€ç®€å•ï¼Œpip installå³å¯ï¼Œæ— éœ€å‚è€ƒè§†é¢‘
2. **VMAF** - æœ€æƒå¨ï¼ŒNetflixç»´æŠ¤ï¼Œè§†é¢‘è´¨é‡è¯„ä¼°é‡‘æ ‡å‡†
3. **IQA-PyTorch** - æœ€å…¨é¢ï¼ŒåŒ…å«å¤šç§æŒ‡æ ‡ï¼Œç»Ÿä¸€API

**å®‰è£…å‘½ä»¤ï¼ˆä¸€é”®å®‰è£…ï¼‰ï¼š**
```bash
pip install lpips vmaf pyiqa
```

è¿™ä¸‰ä¸ªæ¡†æ¶éƒ½æ˜¯ï¼š
- âœ… æœ€å…ˆè¿›çš„æŠ€æœ¯
- âœ… é«˜å‡†ç¡®æ€§
- âœ… å¯ä»¥ç›´æ¥è°ƒç”¨
- âœ… æ–‡æ¡£å®Œå–„
- âœ… ç¤¾åŒºæ´»è·ƒ

---

**åˆ›å»ºæ—¶é—´**ï¼š2025-01-XX
**æœ€åæ›´æ–°**ï¼š2025-01-XX

